{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/lsjsj92/keras_basic/blob/master/7.%20predict_multi_img_with_CNN.ipynb\n",
        "\n",
        "https://lsjsj92.tistory.com/355\n"
      ],
      "metadata": {
        "id": "AoiAI5sDd_AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 라벨링 # 함\n",
        "2. 파일 열기 #함\n",
        "3. 픽셀값으로 변경 # 함\n",
        "4. train, validation 비율 자유 #\n",
        "5. 컨벌루젼 최대 4개, dense 최대 2개 # 이거 모르겠음\n",
        "6. max pooling, dropout 필수 # 함\n",
        "7. 손실함수 : categorical_crossentropy # 함\n",
        "8. early_stopping # 함\n",
        "9. test 데이터 사용해서 예측값과 실제값 비교 시각화 # 해야함\n",
        "sklearn - confusion_matrix\n",
        "seaborn -  heatmap\n",
        "\n",
        "\n",
        "옵션\n",
        "\n",
        "성능 향상을 위해, data augmentation 기법 적용 가능\n",
        "예: rotation [1], jigsaw puzzle [2], colorization [3], and inpainting [4]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y8WNdgY0QYiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n"
      ],
      "metadata": {
        "id": "B8Sp4_BK7hGm"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "라벨링, 파일 불러오기기, 픽셀값 변경경"
      ],
      "metadata": {
        "id": "AObA4kKFQSSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "caltech_dir = './drive/MyDrive/Colab Notebooks/data/train'\n",
        "\n",
        "categories = [\"adidas\", \"converse\", \"nike\"]\n",
        "\n",
        "#caltech_dir = \"./multi_img_data/imgs_others/train\"\n",
        "\n",
        "nb_classes = len(categories)\n",
        "\n",
        "image_w = 240\n",
        "image_h = 240\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(cat, \" : \", f)\n",
        "\n",
        "X = np.array(X) #데이터 쌓기\n",
        "y = np.array(y) # 라벨링 쌓기\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
        "print(\"ok\", len(y))\n",
        "\n",
        "##########################################\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "caltech_dir = './drive/MyDrive/Colab Notebooks/data/test'\n",
        "\n",
        "categories = [\"adidas\", \"converse\", \"nike\"]\n",
        "\n",
        "#caltech_dir = \"./multi_img_data/imgs_others/train\"\n",
        "\n",
        "nb_classes = len(categories)\n",
        "\n",
        "image_w = 240\n",
        "image_h = 240\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X1 = []\n",
        "y1 = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X1.append(data)\n",
        "        y1.append(label)\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(cat, \" : \", f)\n",
        "\n",
        "\n",
        "X_test2 = np.array(X1)\n",
        "y_test2 = np.array(y1)\n",
        "\n",
        "\n",
        "# xy = (X_train, X_test, y_train, y_test)\n",
        "# np.save(\"./drive/MyDrive/Colab Notebooks/data/multi_image_data.npy\", xy)\n",
        "\n",
        "print(\"ok\", len(y_test2))\n",
        "\n",
        "# X_train, X_test, y_train, y_test = np.load('./drive/MyDrive/Colab Notebooks/data/multi_image_data.npy')\n",
        "#print(X_train)\n",
        "#print(X_train.shape[0])\n",
        "\n",
        "\n",
        "# plt.imshow(files[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "bjWLfLaC7hAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a282cbbf-a452-4f7e-9c0d-46cbc14eee5d"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "adidas  파일 길이 :  237\n",
            "adidas  :  ./drive/MyDrive/Colab Notebooks/data/train/adidas/168.jpg\n",
            "converse  파일 길이 :  237\n",
            "converse  :  ./drive/MyDrive/Colab Notebooks/data/train/converse/189.jpg\n",
            "nike  파일 길이 :  237\n",
            "nike  :  ./drive/MyDrive/Colab Notebooks/data/train/nike/129.jpg\n",
            "ok 711\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "adidas  파일 길이 :  38\n",
            "adidas  :  ./drive/MyDrive/Colab Notebooks/data/test/adidas/18.jpg\n",
            "converse  파일 길이 :  38\n",
            "converse  :  ./drive/MyDrive/Colab Notebooks/data/test/converse/32.jpg\n",
            "nike  파일 길이 :  38\n",
            "nike  :  ./drive/MyDrive/Colab Notebooks/data/test/nike/4.jpg\n",
            "ok 114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_test2)"
      ],
      "metadata": {
        "id": "mlHm-TInzEN9"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"adidas\", \"converse\", \"nike\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "#일반화\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255\n",
        "\n",
        "X_test2 = X_test2.astype(float) / 255\n"
      ],
      "metadata": {
        "id": "fkSn9NsTA1SM"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_test2)"
      ],
      "metadata": {
        "id": "sIWZp6Thy5oX"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu')) # 커널의 개수 32개, 커널의 크기 3*3, 입력의 크기 : 행, 열, 흑백 \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Flatten()) # 1차원 백터로 변경경\n",
        "model.add(Dense(512, activation='relu')) # dense 1\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='softmax')) # dense 2\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # 손실함수 : categorical_crossentropy, 옵티마이저 : 아담, 메트릭스 \n",
        "\n",
        "model_dir = './drive/MyDrive/Colab Notebooks/data'\n",
        "\n",
        "model_path = model_dir + '/multi_img_classification.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10) # 얼리 스타핑핑\n",
        "\n",
        "model.summary() #썸머리 \n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs=50, validation_split= 0.25, callbacks=[checkpoint, early_stopping])\n",
        "\n",
        "# validation_data=(X_test, y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVdlrSVSA7ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d6db83-c4d8-4fbf-f176-60f877ae1d2d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 240, 240, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_60 (MaxPoolin  (None, 120, 120, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 120, 120, 16)      0         \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 120, 120, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_61 (MaxPoolin  (None, 60, 60, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 60, 60, 32)        0         \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_62 (MaxPoolin  (None, 30, 30, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 28800)             0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 512)               14746112  \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,761,987\n",
            "Trainable params: 14,761,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "40/43 [==========================>...] - ETA: 0s - loss: 2.1971 - accuracy: 0.3000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 4s 72ms/step - loss: 2.1300 - accuracy: 0.3028 - val_loss: 1.0998 - val_accuracy: 0.2676\n",
            "Epoch 2/50\n",
            "42/43 [============================>.] - ETA: 0s - loss: 1.0986 - accuracy: 0.3429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 3s 73ms/step - loss: 1.0984 - accuracy: 0.3451 - val_loss: 1.0996 - val_accuracy: 0.3873\n",
            "Epoch 3/50\n",
            "42/43 [============================>.] - ETA: 0s - loss: 1.0963 - accuracy: 0.3381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 3s 61ms/step - loss: 1.0963 - accuracy: 0.3380 - val_loss: 1.0989 - val_accuracy: 0.3451\n",
            "Epoch 4/50\n",
            "41/43 [===========================>..] - ETA: 0s - loss: 1.0844 - accuracy: 0.4049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 3s 67ms/step - loss: 1.0834 - accuracy: 0.4108 - val_loss: 1.0976 - val_accuracy: 0.3521\n",
            "Epoch 5/50\n",
            "42/43 [============================>.] - ETA: 0s - loss: 1.0458 - accuracy: 0.4452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 3s 67ms/step - loss: 1.0460 - accuracy: 0.4437 - val_loss: 1.0821 - val_accuracy: 0.4437\n",
            "Epoch 6/50\n",
            "42/43 [============================>.] - ETA: 0s - loss: 0.9543 - accuracy: 0.5286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 3s 60ms/step - loss: 0.9525 - accuracy: 0.5305 - val_loss: 1.0725 - val_accuracy: 0.4577\n",
            "Epoch 7/50\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 0.8378 - accuracy: 0.6244 - val_loss: 1.1019 - val_accuracy: 0.4648\n",
            "Epoch 8/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.7090 - accuracy: 0.6901 - val_loss: 1.3458 - val_accuracy: 0.3803\n",
            "Epoch 9/50\n",
            "43/43 [==============================] - 1s 19ms/step - loss: 0.6059 - accuracy: 0.7113 - val_loss: 1.2739 - val_accuracy: 0.4225\n",
            "Epoch 10/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.5254 - accuracy: 0.7559 - val_loss: 1.3529 - val_accuracy: 0.4155\n",
            "Epoch 11/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.4644 - accuracy: 0.7864 - val_loss: 1.4522 - val_accuracy: 0.4718\n",
            "Epoch 12/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.3997 - accuracy: 0.8146 - val_loss: 1.5742 - val_accuracy: 0.4718\n",
            "Epoch 13/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.3332 - accuracy: 0.8427 - val_loss: 1.8288 - val_accuracy: 0.4366\n",
            "Epoch 14/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.2921 - accuracy: 0.8662 - val_loss: 2.1342 - val_accuracy: 0.4789\n",
            "Epoch 15/50\n",
            "43/43 [==============================] - 1s 20ms/step - loss: 0.3090 - accuracy: 0.8451 - val_loss: 2.0913 - val_accuracy: 0.4859\n",
            "Epoch 16/50\n",
            "43/43 [==============================] - 1s 21ms/step - loss: 0.2581 - accuracy: 0.8709 - val_loss: 2.1733 - val_accuracy: 0.4930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score = model.evaluate(X_test2,y_test2)\n",
        "# print(score)\n",
        "\n",
        "# print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "id": "J6h_N9h9x5lh"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "real_prices = []\n",
        "pred_prices = []\n",
        "X_num = []\n",
        "n_iter=0\n",
        "\n",
        "filenames = []\n",
        "\n",
        "Y_prediction = model.predict(X_test2)\n",
        "\n",
        "# print(Y_prediction) \n",
        "\n",
        "\n",
        "for i in range(len(X_test2)):\n",
        "  real = y_test[i]\n",
        "  prediction = Y_prediction[i]\n",
        "  # print('Real price : {}, Expected price : {}'.format(real,prediction))\n",
        "  real_prices.append(real)\n",
        "  pred_prices.append(prediction)\n",
        "  n_iter = n_iter +1\n",
        "  X_num.append(n_iter)\n",
        "\n",
        "# print(type(real_prices))\n",
        "# print(type(pred_prices))\n",
        "\n",
        "# print(real_prices)\n",
        "# print(pred_prices)\n",
        "\n",
        "\n",
        "# confusion_matrix(real_prices, pred_prices)\n",
        "\n"
      ],
      "metadata": {
        "id": "U150l6khkjO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc8ae81-942b-45f1-b8d9-43f45e8e42b6"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(pred_prices)"
      ],
      "metadata": {
        "id": "zSEQ6YpNyh70"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "\n",
        "for i in pred_prices:\n",
        "  if(i.argmax()== 0):\n",
        "    pred.append(0)\n",
        "  elif(i.argmax()== 1):\n",
        "    pred.append(1)\n",
        "  elif(i.argmax()== 2):\n",
        "    pred.append(2)\n",
        "\n",
        "Y_test = []\n",
        "\n",
        "for i in y_test2:\n",
        "  if(i.argmax()== 0):\n",
        "    Y_test.append(0)\n",
        "  elif(i.argmax()== 1):\n",
        "    Y_test.append(1)\n",
        "  elif(i.argmax()== 2):\n",
        "    Y_test.append(2)\n",
        "\n"
      ],
      "metadata": {
        "id": "zdTOCaaO1oqW"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = confusion_matrix(Y_test, pred)"
      ],
      "metadata": {
        "id": "Hy6868BL02cA"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (3, 3))\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predict')\n",
        "sns.heatmap(test, linewidth = 30, vmax = 30, cmap = 'Reds', annot = True)\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8paOJRW8dee-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "007ee87c-e9d9-4996-aaf2-c606ec82258a"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}